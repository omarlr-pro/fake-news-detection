
# ğŸ“° Fake News Detection Web App

This project is a web-based Fake News Detection system built with **Streamlit** and trained using **Logistic Regression** and **Naive Bayes** models. It uses **TF-IDF vectorization** and processes real and fake news articles to classify them accurately.

---

## ğŸš€ Features

- Binary classification: **Real vs Fake news**
- Choose between **Logistic Regression** and **Naive Bayes**
- Cleaned and preprocessed news data
- Streamlit interface for interactive usage
- Trained models and vectorizer stored in `models/` folder
- Custom preprocessing with **NLTK**, **lemmatization**, and **stopword removal**

---

## ğŸ“ Project Structure

```
.
â”œâ”€â”€ app.py                # Streamlit app for real-time prediction
â”œâ”€â”€ train_model.py        # Script to clean data, train models and save them
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ Fake.csv          # Dataset containing fake news
â”‚   â””â”€â”€ True.csv          # Dataset containing real news
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ logistic_model.pkl
â”‚   â”œâ”€â”€ naive_bayes.pkl
â”‚   â””â”€â”€ vectorizer.pkl
â””â”€â”€ README.md             # Project documentation
```

---

## ğŸ“· Screenshot

![Screenshot](assets/Screenshot2025-05-09172828.png)
![Screenshot](assets/Screenshot2025-05-09173048.png)
![Screenshot](assets/Screenshot2025-05-09172828.png)



---

## ğŸ§ª How It Works

1. Load datasets from `data/Fake.csv` and `data/True.csv`
2. Label them (Fake=1, Real=0)
3. Preprocess text:
   - Lowercasing
   - Remove punctuation
   - Remove stopwords
   - Lemmatization
4. Train models using TF-IDF + Logistic Regression / Naive Bayes
5. Save models in `models/` using `pickle`
6. Load in Streamlit to predict and visualize results interactively

---

## ğŸ“¦ Installation

### 1. Clone the repository

```bash
git clone https://github.com/your-username/fake-news-detector.git
cd fake-news-detector
```

### 2. Create a virtual environment

```bash
python -m venv .venv
# Activate it:
# On Windows:
.venv\Scripts\activate
# On macOS/Linux:
source .venv/bin/activate
```

### 3. Install dependencies

```bash
pip install --upgrade pip setuptools wheel
pip install -r requirements.txt
```

### 4. Run the project

```bash
python train_model.py     # Preprocesses data, trains and saves models
streamlit run app.py      # Launches the web app
```

---

## âœ… Requirements

Hereâ€™s the content for `requirements.txt`:

```
streamlit
pandas
numpy
scikit-learn
nltk
```

---

## ğŸ§  Models Used

- **Logistic Regression** â€“ fast linear classifier
- **Multinomial Naive Bayes** â€“ well-suited for word frequencies
- **TF-IDF Vectorizer** â€“ converts text to numerical vectors

---

## ğŸ“‚ Datasets

Used Kaggle's [Fake and Real News Dataset](https://www.kaggle.com/clmentbisaillon/fake-and-real-news-dataset)

Place both CSVs inside the `data/` directory:

- `data/Fake.csv`
- `data/True.csv`

---


---

## ğŸ™‹â€â™‚ï¸ Author

- **Omar Laraje**  
  [GitHub](https://github.com/omarlr-pro)  
  [LinkedIn](https://www.linkedin.com/in/omar-laraje-998827233/)  
  
